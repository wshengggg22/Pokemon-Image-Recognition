A CNN-based deep learning system to identify Pokémon from images in various styles (sprites, anime, 3D). Built for APS360, this project demonstrates automated Pokémon recognition, with potential applications in digital Pokédex tools and educational games.

The primary motivation for this project lies in the global popularity of Pokémon. According to the National Pokédex, there are 1,025 distinct Pokémon species as of 2025, each with its own unique design, abilities, and description. Developing a deep learning system capable of recognizing these Pokémon from images is both an engaging and meaningful task, as it could serve as the foundation for applications such as automated Pokédex tools or educational games. Deep learning is a natural choice for this problem because Pokémon appear in diverse visual styles (e.g., sprites, anime artwork, and 3D renders). Traditional image processing methods struggle to handle such variation, as they rely on hand-crafted features that do not generalize well across different art styles. In contrast, convolutional neural networks (CNNs) can automatically learn hierarchical visual features such as edges, colors, and textures which should remain consistent across these variations. In this project, I will fine-tune a pretrained ResNet-18 model on the 7,000 Labeled Pokémon dataset from Kaggle, which contains images of 150 Pokémon species. Leveraging transfer learning allows the model to adapt existing visual knowledge from large-scale datasets (like ImageNet) to recognize Pokémon effectively, even when encountering unseen styles or renderings.
